import os, json, httpx, re
from typing import Dict, Any, Tuple, List, Optional
import copy
import uuid
from datetime import datetime
from dataclasses import dataclass

# Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Gemini API
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY", "")
GEMINI_MODEL = os.getenv("GEMINI_MODEL", "gemini-1.5-flash")

@dataclass
class WorkflowAnalysis:
    """ØªØ­Ù„ÙŠÙ„ Ø´Ø§Ù…Ù„ Ù„Ø·Ù„Ø¨ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…"""
    trigger_type: str
    services: List[str]
    operations: List[str]
    data_fields: Dict[str, str]
    custom_names: Dict[str, str]  # Ø£Ø³Ù…Ø§Ø¡ Ù…Ø®ØµØµØ© Ù„Ù„Ø¬Ø¯Ø§ÙˆÙ„ØŒ Ø§Ù„Ù‚Ù†ÙˆØ§ØªØŒ Ø¥Ù„Ø®
    business_logic: List[str]
    complexity_score: int
    confidence_level: str
    suggested_templates: List[str]

# Ù†Ø¸Ø§Ù… ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø·Ù„Ø¨Ø§Øª Ø§Ù„Ù…ØªÙ‚Ø¯Ù…
ADVANCED_ANALYZER_PROMPT = """Ø£Ù†Øª Ø®Ø¨ÙŠØ± ÙÙŠ ØªØ­Ù„ÙŠÙ„ Ø·Ù„Ø¨Ø§Øª Ø§Ù„Ø£ØªÙ…ØªØ© ÙˆØªØ­ÙˆÙŠÙ„Ù‡Ø§ Ù„Ù€ workflows n8n Ø¹Ø§Ù„ÙŠØ© Ø§Ù„Ø¬ÙˆØ¯Ø©.

Ù…Ù‡Ù…ØªÙƒ: ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø·Ù„Ø¨ Ø¨Ø¹Ù…Ù‚ Ø´Ø¯ÙŠØ¯ ÙˆØ§Ø³ØªØ®Ø±Ø§Ø¬ ÙƒÙ„ Ø§Ù„ØªÙØ§ØµÙŠÙ„ Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø©.

Ø§Ø³ØªØ®Ø±Ø¬:
1. Ù†ÙˆØ¹ Ø§Ù„ØªØ´ØºÙŠÙ„ (webhook/schedule/manual/email)
2. Ø§Ù„Ø®Ø¯Ù…Ø§Øª Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø© Ù…Ø¹ ØªÙØ§ØµÙŠÙ„Ù‡Ø§
3. Ø£Ø³Ù…Ø§Ø¡ Ù…Ø®ØµØµØ© (Ø¬Ø¯Ø§ÙˆÙ„ØŒ Ù‚Ù†ÙˆØ§ØªØŒ Ø­Ù‚ÙˆÙ„)
4. Ù…Ù†Ø·Ù‚ Ø§Ù„Ø¹Ù…Ù„ ÙˆØ§Ù„Ø´Ø±ÙˆØ·
5. Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø·Ù„ÙˆØ¨ Ù…Ø¹Ø§Ù„Ø¬ØªÙ‡Ø§
6. Ø§Ù„ØªØ®ØµÙŠØµØ§Øª Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø©

Ø£Ø¬Ø¨ Ø¨ØªÙ†Ø³ÙŠÙ‚ JSON Ø¯Ù‚ÙŠÙ‚:
{
  "trigger_type": "...",
  "services": ["service1", "service2"],
  "operations": ["operation1", "operation2"],
  "data_fields": {"field1": "description", "field2": "description"},
  "custom_names": {"sheet_name": "Ø§Ù„Ø¹Ù…Ù„Ø§Ø¡ Ø§Ù„Ø¬Ø¯Ø¯", "channel": "#sales"},
  "business_logic": ["generate unique ID", "send welcome message"],
  "complexity_score": 1-10,
  "confidence_level": "high/medium/low",
  "suggested_templates": ["template1", "template2"]
}

ÙƒÙ† Ø¯Ù‚ÙŠÙ‚Ø§Ù‹ Ø¬Ø¯Ø§Ù‹ ÙÙŠ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ù…Ø®ØµØµØ© ÙˆØ§Ù„ØªÙØ§ØµÙŠÙ„."""

WORKFLOW_CUSTOMIZER_PROMPT = """Ø£Ù†Øª Ù…Ø·ÙˆØ± workflows Ø®Ø¨ÙŠØ± ÙÙŠ n8n. Ù…Ù‡Ù…ØªÙƒ Ø¥Ù†Ø´Ø§Ø¡ workflow Ù…Ø®ØµØµ 100% Ø­Ø³Ø¨ Ø§Ù„ØªØ­Ù„ÙŠÙ„.

Ù‚ÙˆØ§Ø¹Ø¯ Ø§Ù„ØªØ®ØµÙŠØµ Ø§Ù„Ù…ØªÙ‚Ø¯Ù…Ø©:
1. Ø§Ø±Ø¨Ø· ÙƒÙ„ Ø¹Ù‚Ø¯Ø© Ø¨Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ù‚Ø¯Ù…
2. Ø®ØµØµ parameters Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„ØªÙØ§ØµÙŠÙ„ Ø§Ù„Ù…Ø­Ø¯Ø¯Ø©
3. Ø£Ø¶Ù Ø¹Ù‚Ø¯ Ø¥Ø¶Ø§ÙÙŠØ© Ø­Ø³Ø¨ Ø§Ù„Ø­Ø§Ø¬Ø© (Set, Function, IF)
4. Ø§Ø³ØªØ®Ø¯Ù… Ø§Ù„Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ù…Ø®ØµØµØ© Ù…Ù† Ø§Ù„ØªØ­Ù„ÙŠÙ„
5. Ø·Ø¨Ù‚ Ù…Ù†Ø·Ù‚ Ø§Ù„Ø¹Ù…Ù„ Ø§Ù„Ù…Ø·Ù„ÙˆØ¨
6. Ø£Ø¶Ù Ù…Ø¹Ø§Ù„Ø¬Ø© Ø£Ø®Ø·Ø§Ø¡ Ù…ØªÙ‚Ø¯Ù…Ø©

Ø£Ù†ØªØ¬ JSON ÙƒØ§Ù…Ù„ ÙˆØµØ§Ù„Ø­ Ù„Ù„Ø§Ø³ØªÙŠØ±Ø§Ø¯ ÙÙŠ n8n.
Ø§Ø³ØªØ®Ø¯Ù… Ø£Ø­Ø¯Ø« Ø¥ØµØ¯Ø§Ø±Ø§Øª Ø§Ù„Ø¹Ù‚Ø¯ ÙˆØ£ÙØ¶Ù„ Ø§Ù„Ù…Ù…Ø§Ø±Ø³Ø§Øª."""

class AdvancedWorkflowLibrary:
    """Ù…ÙƒØªØ¨Ø© workflows Ù…ØªÙ‚Ø¯Ù…Ø© Ù…Ø¹ Ù†Ø¸Ø§Ù… Ø¨Ø­Ø« Ø°ÙƒÙŠ"""
    
    def __init__(self):
        self.workflows = []
        self.indexed_patterns = {}
        self.load_library()
    
    def load_library(self):
        """ØªØ­Ù…ÙŠÙ„ Ù…ÙƒØªØ¨Ø© Ø§Ù„Ù€ 100 workflow"""
        try:
            # ØªØ­Ù…ÙŠÙ„ Ù…Ù† Ù…Ù„Ù JSON Ø£Ùˆ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
            library_path = os.path.join(os.path.dirname(__file__), "workflows_library.json")
            if os.path.exists(library_path):
                with open(library_path, "r", encoding="utf-8") as f:
                    self.workflows = json.load(f)
                self.index_workflows()
                print(f"[INFO] Loaded {len(self.workflows)} workflows from library")
            else:
                print("[WARNING] Workflows library not found, creating sample data")
                self.create_sample_library()
        except Exception as e:
            print(f"[ERROR] Failed to load workflows library: {e}")
            self.create_sample_library()
    
    def create_sample_library(self):
        """Ø¥Ù†Ø´Ø§Ø¡ Ø¹ÙŠÙ†Ø© Ù…Ù† Ø§Ù„Ù…ÙƒØªØ¨Ø© Ù„Ù„Ø§Ø®ØªØ¨Ø§Ø±"""
        self.workflows = [
            {
                "name": "Advanced Contact Form with Email Automation",
                "description": "Webhook receives form data, saves to custom Google Sheet, sends personalized email with ticket number",
                "tags": ["webhook", "google-sheets", "gmail", "form", "automation"],
                "trigger_types": ["webhook"],
                "services": ["google-sheets", "gmail"],
                "complexity": "medium",
                "pattern_keywords": ["form", "contact", "email", "sheet", "ticket", "number"],
                "json_template": {
                    # Template workflow structure...
                }
            }
            # Ø§Ù„Ù…Ø²ÙŠØ¯ Ù…Ù† Ø§Ù„Ù€ workflows...
        ]
        self.index_workflows()
    
    def index_workflows(self):
        """ÙÙ‡Ø±Ø³Ø© Ø§Ù„Ù€ workflows Ù„Ù„Ø¨Ø­Ø« Ø§Ù„Ø³Ø±ÙŠØ¹"""
        self.indexed_patterns = {}
        for i, workflow in enumerate(self.workflows):
            # ÙÙ‡Ø±Ø³Ø© Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…ÙØªØ§Ø­ÙŠØ©
            for keyword in workflow.get("pattern_keywords", []):
                if keyword not in self.indexed_patterns:
                    self.indexed_patterns[keyword] = []
                self.indexed_patterns[keyword].append(i)
    
    def find_relevant_workflows(self, analysis: WorkflowAnalysis, max_results=5) -> List[Dict]:
        """Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† workflows Ù…Ù†Ø§Ø³Ø¨Ø© Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„ØªØ­Ù„ÙŠÙ„"""
        relevant = []
        scores = {}
        
        # Ø§Ù„Ø¨Ø­Ø« ÙÙŠ Ø§Ù„ÙÙ‡Ø±Ø³
        search_terms = (
            analysis.services + 
            analysis.operations + 
            [analysis.trigger_type] +
            list(analysis.custom_names.keys()) +
            list(analysis.custom_names.values())
        )
        
        for term in search_terms:
            term_lower = term.lower()
            for keyword, workflow_indices in self.indexed_patterns.items():
                if term_lower in keyword.lower() or keyword.lower() in term_lower:
                    for idx in workflow_indices:
                        if idx not in scores:
                            scores[idx] = 0
                        scores[idx] += 1
        
        # ØªØ±ØªÙŠØ¨ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ ÙˆØ¥Ø±Ø¬Ø§Ø¹ Ø§Ù„Ø£ÙØ¶Ù„
        sorted_workflows = sorted(scores.items(), key=lambda x: x[1], reverse=True)
        for idx, score in sorted_workflows[:max_results]:
            workflow = copy.deepcopy(self.workflows[idx])
            workflow["relevance_score"] = score
            relevant.append(workflow)
        
        return relevant

class AdvancedN8NBuilder:
    """Ø¨Ù†Ø§Ø¡ workflows n8n Ù…ØªÙ‚Ø¯Ù…Ø© ÙˆÙ…Ø®ØµØµØ©"""
    
    def __init__(self):
        self.library = AdvancedWorkflowLibrary()
    
    def build_custom_workflow(self, analysis: WorkflowAnalysis, relevant_workflows: List[Dict]) -> Dict[str, Any]:
        """Ø¨Ù†Ø§Ø¡ workflow Ù…Ø®ØµØµ Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„ØªØ­Ù„ÙŠÙ„ ÙˆØ§Ù„Ù…Ø±Ø§Ø¬Ø¹"""
        
        # Ø§Ø®ØªÙŠØ§Ø± Ø£ÙØ¶Ù„ Ù‚Ø§Ù„Ø¨ ÙƒØ£Ø³Ø§Ø³
        base_template = self._select_best_template(analysis, relevant_workflows)
        
        # ØªØ®ØµÙŠØµ Ø§Ù„Ù€ workflow
        customized = self._customize_workflow(base_template, analysis)
        
        # Ø¥Ø¶Ø§ÙØ© Ø¹Ù‚Ø¯ Ø¥Ø¶Ø§ÙÙŠØ© Ø­Ø³Ø¨ Ø§Ù„Ø­Ø§Ø¬Ø©
        enhanced = self._enhance_workflow(customized, analysis)
        
        # Ø§Ù„ØªØ­Ù‚Ù‚ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ ÙˆØ§Ù„ØªÙ†Ø¸ÙŠÙ
        final_workflow = self._finalize_workflow(enhanced, analysis)
        
        return final_workflow
    
    def _select_best_template(self, analysis: WorkflowAnalysis, relevant_workflows: List[Dict]) -> Dict[str, Any]:
        """Ø§Ø®ØªÙŠØ§Ø± Ø£ÙØ¶Ù„ Ù‚Ø§Ù„Ø¨ Ø£Ø³Ø§Ø³ÙŠ"""
        if relevant_workflows:
            # Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø£ÙƒØ«Ø± Ù…Ù„Ø§Ø¡Ù…Ø© Ù…Ù† Ø§Ù„Ù…ÙƒØªØ¨Ø©
            best_match = relevant_workflows[0]
            return best_match.get("json_template", self._get_fallback_template(analysis))
        else:
            # Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù‚Ø§Ù„Ø¨ Ø§Ø­ØªÙŠØ§Ø·ÙŠ
            return self._get_fallback_template(analysis)
    
    def _get_fallback_template(self, analysis: WorkflowAnalysis) -> Dict[str, Any]:
        """Ù‚Ø§Ù„Ø¨ Ø§Ø­ØªÙŠØ§Ø·ÙŠ Ø£Ø³Ø§Ø³ÙŠ"""
        if analysis.trigger_type == "webhook" and "google-sheets" in analysis.services:
            return self._create_webhook_sheets_template()
        elif analysis.trigger_type == "schedule":
            return self._create_schedule_template()
        else:
            return self._create_minimal_template()
    
    def _customize_workflow(self, template: Dict[str, Any], analysis: WorkflowAnalysis) -> Dict[str, Any]:
        """ØªØ®ØµÙŠØµ Ø´Ø§Ù…Ù„ Ù„Ù„Ù€ workflow"""
        workflow = copy.deepcopy(template)
        
        # ØªØ­Ø¯ÙŠØ« Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ù€ workflow
        workflow["name"] = self._generate_workflow_name(analysis)
        workflow["updatedAt"] = datetime.now().isoformat()
        
        # ØªØ®ØµÙŠØµ Ø§Ù„Ø¹Ù‚Ø¯
        for node in workflow.get("nodes", []):
            self._customize_node(node, analysis)
        
        return workflow
    
    def _customize_node(self, node: Dict[str, Any], analysis: WorkflowAnalysis):
        """ØªØ®ØµÙŠØµ Ø¹Ù‚Ø¯Ø© ÙˆØ§Ø­Ø¯Ø© Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„ØªØ­Ù„ÙŠÙ„"""
        node_type = node.get("type", "")
        
        if "googleSheets" in node_type:
            self._customize_sheets_node(node, analysis)
        elif "gmail" in node_type:
            self._customize_gmail_node(node, analysis)
        elif "slack" in node_type:
            self._customize_slack_node(node, analysis)
        elif "webhook" in node_type:
            self._customize_webhook_node(node, analysis)
    
    def _customize_sheets_node(self, node: Dict[str, Any], analysis: WorkflowAnalysis):
        """ØªØ®ØµÙŠØµ Ø¹Ù‚Ø¯Ø© Google Sheets"""
        params = node.setdefault("parameters", {})
        
        # Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ø³Ù… Ø§Ù„Ø¬Ø¯ÙˆÙ„ Ø§Ù„Ù…Ø®ØµØµ
        if "sheet_name" in analysis.custom_names:
            params["sheetName"] = {
                "__rl": True,
                "value": analysis.custom_names["sheet_name"],
                "mode": "list"
            }
        
        # ØªØ®ØµÙŠØµ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø©
        if analysis.data_fields:
            columns_mapping = {}
            for field_key, field_desc in analysis.data_fields.items():
                # ØªØ­ÙˆÙŠÙ„ Ø§Ø³Ù… Ø§Ù„Ø­Ù‚Ù„ Ù„Ø§Ø³Ù… Ø¹Ù…ÙˆØ¯ Ù…Ù†Ø§Ø³Ø¨
                column_name = field_desc.title() if field_desc else field_key.title()
                columns_mapping[column_name] = f"={{{{ $json.{field_key} }}}}"
            
            # Ø¥Ø¶Ø§ÙØ© Ø­Ù‚ÙˆÙ„ Ø¥Ø¶Ø§ÙÙŠØ© Ø­Ø³Ø¨ Ù…Ù†Ø·Ù‚ Ø§Ù„Ø¹Ù…Ù„
            if "generate unique ID" in analysis.business_logic:
                columns_mapping["Request_ID"] = "={{ 'REQ-' + new Date().getTime().toString() }}"
            
            if "timestamp" not in columns_mapping:
                columns_mapping["Timestamp"] = "={{ new Date().toISOString() }}"
            
            params["columns"] = {
                "mappingMode": "defineBelow",
                "value": columns_mapping,
                "matchingColumns": [],
                "schema": []
            }
    
    def _customize_gmail_node(self, node: Dict[str, Any], analysis: WorkflowAnalysis):
        """ØªØ®ØµÙŠØµ Ø¹Ù‚Ø¯Ø© Gmail"""
        params = node.setdefault("parameters", {})
        
        # ØªØ®ØµÙŠØµ Ù…ÙˆØ¶ÙˆØ¹ Ø§Ù„Ø±Ø³Ø§Ù„Ø©
        if "welcome" in analysis.business_logic:
            params["subject"] = "Ù…Ø±Ø­Ø¨Ø§Ù‹ Ø¨Ùƒ! ØªÙ… Ø§Ø³ØªÙ„Ø§Ù… Ø·Ù„Ø¨Ùƒ"
        
        # ØªØ®ØµÙŠØµ Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ø±Ø³Ø§Ù„Ø© Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
        message_parts = ["Ø¹Ø²ÙŠØ²ÙŠ/Ø¹Ø²ÙŠØ²ØªÙŠ {{ $json.name || 'Ø§Ù„Ø¹Ù…ÙŠÙ„' }}ØŒ\n\n"]
        
        if "generate unique ID" in analysis.business_logic:
            message_parts.append("Ø±Ù‚Ù… Ø·Ù„Ø¨Ùƒ: {{ 'REQ-' + new Date().getTime().toString() }}\n\n")
        
        message_parts.extend([
            "Ø´ÙƒØ±Ø§Ù‹ Ù„Ùƒ Ø¹Ù„Ù‰ ØªÙˆØ§ØµÙ„Ùƒ Ù…Ø¹Ù†Ø§. Ø³ÙŠØªÙ… Ø§Ù„Ø±Ø¯ Ø¹Ù„ÙŠÙƒ Ù‚Ø±ÙŠØ¨Ø§Ù‹.\n\n",
            "ØªÙØ§ØµÙŠÙ„ Ø·Ù„Ø¨Ùƒ:\n"
        ])
        
        # Ø¥Ø¶Ø§ÙØ© ØªÙØ§ØµÙŠÙ„ Ø§Ù„Ø·Ù„Ø¨
        for field_key, field_desc in analysis.data_fields.items():
            if field_key != "name":
                message_parts.append(f"- {field_desc}: {{{{ $json.{field_key} }}}}\n")
        
        message_parts.append("\n\nÙ…Ø¹ Ø£Ø·ÙŠØ¨ Ø§Ù„ØªØ­ÙŠØ§ØªØŒ\nÙØ±ÙŠÙ‚ Ø§Ù„Ø¯Ø¹Ù…")
        
        params["message"] = "".join(message_parts)
    
    def _enhance_workflow(self, workflow: Dict[str, Any], analysis: WorkflowAnalysis) -> Dict[str, Any]:
        """ØªØ­Ø³ÙŠÙ† Ø§Ù„Ù€ workflow Ø¨Ø¥Ø¶Ø§ÙØ© Ø¹Ù‚Ø¯ Ø¥Ø¶Ø§ÙÙŠØ©"""
        
        # Ø¥Ø¶Ø§ÙØ© Ø¹Ù‚Ø¯Ø© Set Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¥Ø°Ø§ Ù„Ø²Ù… Ø§Ù„Ø£Ù…Ø±
        if self._needs_data_processing(analysis):
            self._add_set_node(workflow, analysis)
        
        # Ø¥Ø¶Ø§ÙØ© Ø¹Ù‚Ø¯Ø© IF Ù„Ù„Ø´Ø±ÙˆØ· Ø§Ù„Ù…Ù†Ø·Ù‚ÙŠØ©
        if self._needs_conditional_logic(analysis):
            self._add_if_node(workflow, analysis)
        
        # Ø¥Ø¶Ø§ÙØ© Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø£Ø®Ø·Ø§Ø¡
        self._add_error_handling(workflow)
        
        return workflow
    
    def _needs_data_processing(self, analysis: WorkflowAnalysis) -> bool:
        """ØªØ­Ø¯ÙŠØ¯ Ø¥Ø°Ø§ ÙƒØ§Ù† Ù‡Ù†Ø§Ùƒ Ø­Ø§Ø¬Ø© Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª"""
        return any(logic in analysis.business_logic for logic in 
                  ["generate unique ID", "transform data", "calculate", "format"])
    
    def _add_set_node(self, workflow: Dict[str, Any], analysis: WorkflowAnalysis):
        """Ø¥Ø¶Ø§ÙØ© Ø¹Ù‚Ø¯Ø© Set Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª"""
        set_node = {
            "parameters": {
                "values": {},
                "options": {}
            },
            "id": str(uuid.uuid4())[:8],
            "name": "Process Data",
            "type": "n8n-nodes-base.set",
            "typeVersion": 3,
            "position": [340, 300]
        }
        
        # ØªÙƒÙˆÙŠÙ† Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ù…Ø·Ù„ÙˆØ¨ Ù…Ø¹Ø§Ù„Ø¬ØªÙ‡Ø§
        values = {}
        if "generate unique ID" in analysis.business_logic:
            values["request_id"] = "={{ 'REQ-' + new Date().getTime().toString() }}"
        
        set_node["parameters"]["values"] = {"string": [{"name": k, "value": v} for k, v in values.items()]}
        
        # Ø¥Ø¯Ø±Ø§Ø¬ Ø§Ù„Ø¹Ù‚Ø¯Ø© ÙÙŠ Ø§Ù„Ù…ÙˆÙ‚Ø¹ Ø§Ù„Ù…Ù†Ø§Ø³Ø¨
        workflow["nodes"].insert(1, set_node)
        self._update_connections_for_new_node(workflow, set_node["id"], 1)
    
    def _finalize_workflow(self, workflow: Dict[str, Any], analysis: WorkflowAnalysis) -> Dict[str, Any]:
        """Ø§Ù„ØªØ´Ø·ÙŠØ¨ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ Ù„Ù„Ù€ workflow"""
        
        # ØªØ­Ø¯ÙŠØ« Ù…Ø¹Ø±ÙØ§Øª Ø§Ù„Ø¹Ù‚Ø¯
        self._update_node_ids(workflow)
        
        # ØªØ­Ø¯ÙŠØ« Ø§Ù„Ø§ØªØµØ§Ù„Ø§Øª
        self._validate_connections(workflow)
        
        # Ø¥Ø¶Ø§ÙØ© metadata
        workflow.setdefault("tags", []).extend(analysis.services)
        workflow["description"] = f"Custom workflow for: {', '.join(analysis.operations)}"
        
        return workflow
    
    # Helper methods for template creation
    def _create_webhook_sheets_template(self) -> Dict[str, Any]:
        """Ù‚Ø§Ù„Ø¨ webhook Ø¥Ù„Ù‰ sheets Ø£Ø³Ø§Ø³ÙŠ"""
        return {
            "active": True,
            "connections": {},
            "createdAt": datetime.now().isoformat(),
            "updatedAt": datetime.now().isoformat(),
            "id": "1",
            "name": "Custom Webhook to Sheets",
            "nodes": [
                {
                    "parameters": {
                        "httpMethod": "POST",
                        "path": "contact-form",
                        "responseMode": "onReceived",
                        "options": {}
                    },
                    "id": str(uuid.uuid4())[:8],
                    "name": "Webhook",
                    "type": "n8n-nodes-base.webhook",
                    "typeVersion": 2,
                    "position": [240, 300],
                    "webhookId": str(uuid.uuid4())[:8]
                }
            ],
            "pinData": {},
            "settings": {"executionOrder": "v1"},
            "staticData": {},
            "tags": [],
            "triggerCount": 1,
            "versionId": "1"
        }
    
    def _generate_workflow_name(self, analysis: WorkflowAnalysis) -> str:
        """ØªÙˆÙ„ÙŠØ¯ Ø§Ø³Ù… Ù…Ù†Ø§Ø³Ø¨ Ù„Ù„Ù€ workflow"""
        name_parts = []
        
        if analysis.trigger_type == "webhook":
            name_parts.append("Form")
        elif analysis.trigger_type == "schedule":
            name_parts.append("Scheduled")
        
        if "google-sheets" in analysis.services:
            name_parts.append("to Sheets")
        
        if "gmail" in analysis.services:
            name_parts.append("with Email")
        
        if "slack" in analysis.services:
            name_parts.append("Slack Notification")
        
        # Ø¥Ø¶Ø§ÙØ© Ø§Ù„ØªØ®ØµÙŠØµ Ø¥Ø°Ø§ ÙˆØ¬Ø¯
        if analysis.custom_names:
            custom_part = list(analysis.custom_names.values())[0]
            name_parts.append(f"({custom_part})")
        
        return " ".join(name_parts) or "Custom Automation"

async def _call_gemini_api(prompt: str, system_instruction: str = "") -> str:
    """Ø§Ø³ØªØ¯Ø¹Ø§Ø¡ Gemini API Ù…Ø­Ø³Ù†"""
    if not GEMINI_API_KEY:
        raise RuntimeError("GEMINI_API_KEY not configured")
    
    url = f"https://generativelanguage.googleapis.com/v1beta/models/{GEMINI_MODEL}:generateContent?key={GEMINI_API_KEY}"
    
    contents = []
    if system_instruction:
        contents.append({
            "role": "model",
            "parts": [{"text": system_instruction}]
        })
    
    contents.append({
        "role": "user", 
        "parts": [{"text": prompt}]
    })
    
    payload = {
        "contents": contents,
        "generationConfig": {
            "temperature": 0.1,  # Ø£Ù‚Ù„ Ù„Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ù†ØªØ§Ø¦Ø¬ Ø£ÙƒØ«Ø± Ø¯Ù‚Ø©
            "maxOutputTokens": 4000,  # Ø£ÙƒØ«Ø± Ù„Ù„Ù€ workflows Ø§Ù„Ù…Ø¹Ù‚Ø¯Ø©
            "topP": 0.8,
            "topK": 40
        }
    }
    
    async with httpx.AsyncClient(timeout=90) as client:
        response = await client.post(url, json=payload)
        
        if response.status_code != 200:
            raise RuntimeError(f"Gemini API returned {response.status_code}")
        
        data = response.json()
        
        if not data.get("candidates") or not data["candidates"][0].get("content"):
            raise RuntimeError("No valid response from Gemini")
        
        return data["candidates"][0]["content"]["parts"][0]["text"].strip()

async def analyze_user_request_advanced(user_prompt: str) -> WorkflowAnalysis:
    """ØªØ­Ù„ÙŠÙ„ Ù…ØªÙ‚Ø¯Ù… Ù„Ø·Ù„Ø¨ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…"""
    try:
        analysis_prompt = f"""
Ø·Ù„Ø¨ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…: "{user_prompt}"

Ø­Ù„Ù„ Ù‡Ø°Ø§ Ø§Ù„Ø·Ù„Ø¨ Ø¨Ø¹Ù…Ù‚ ÙˆØ§Ø³ØªØ®Ø±Ø¬ ÙƒÙ„ Ø§Ù„ØªÙØ§ØµÙŠÙ„ Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø©.
Ø±ÙƒØ² Ø¹Ù„Ù‰:
- Ø§Ù„Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ù…Ø­Ø¯Ø¯Ø© (Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ø¬Ø¯Ø§ÙˆÙ„ØŒ Ø§Ù„Ù‚Ù†ÙˆØ§ØªØŒ Ø§Ù„Ø­Ù‚ÙˆÙ„)
- Ù…Ù†Ø·Ù‚ Ø§Ù„Ø¹Ù…Ù„ Ø§Ù„Ù…Ø·Ù„ÙˆØ¨
- Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø·Ù„ÙˆØ¨ Ù…Ø¹Ø§Ù„Ø¬ØªÙ‡Ø§
- Ø§Ù„ØªØ®ØµÙŠØµØ§Øª Ø§Ù„Ù…Ø­Ø¯Ø¯Ø©

Ø£Ø¬Ø¨ Ø¨Ù€ JSON ØµØ§Ù„Ø­ ÙÙ‚Ø· Ø¨Ø¯ÙˆÙ† Ø£ÙŠ Ù†Øµ Ø¥Ø¶Ø§ÙÙŠ.
"""
        
        response = await _call_gemini_api(analysis_prompt, ADVANCED_ANALYZER_PROMPT)
        
        # Ø§Ø³ØªØ®Ø±Ø§Ø¬ JSON Ù…Ù† Ø§Ù„Ø§Ø³ØªØ¬Ø§Ø¨Ø©
        json_match = re.search(r'\{.*\}', response, re.DOTALL)
        if json_match:
            analysis_data = json.loads(json_match.group())
            return WorkflowAnalysis(**analysis_data)
        else:
            raise ValueError("Failed to extract JSON from AI response")
            
    except Exception as e:
        print(f"[WARNING] Advanced analysis failed: {e}")
        # ØªØ­Ù„ÙŠÙ„ Ø§Ø­ØªÙŠØ§Ø·ÙŠ Ù…Ø¨Ø³Ø·
        return _fallback_analysis(user_prompt)

def _fallback_analysis(user_prompt: str) -> WorkflowAnalysis:
    """ØªØ­Ù„ÙŠÙ„ Ø§Ø­ØªÙŠØ§Ø·ÙŠ Ù…Ø¨Ø³Ø·"""
    return WorkflowAnalysis(
        trigger_type="webhook",
        services=["google-sheets"] if "sheet" in user_prompt.lower() else ["basic"],
        operations=["save_data"],
        data_fields={"name": "Name", "email": "Email", "message": "Message"},
        custom_names={},
        business_logic=[],
        complexity_score=5,
        confidence_level="medium",
        suggested_templates=["webhook_to_sheets"]
    )

async def plan_workflow_with_ai_advanced(user_prompt: str) -> Tuple[str, bool]:
    """ØªØ®Ø·ÙŠØ· workflow Ù…ØªÙ‚Ø¯Ù…"""
    try:
        print(f"[INFO] Advanced analysis starting: {user_prompt[:100]}...")
        
        # ØªØ­Ù„ÙŠÙ„ Ø´Ø§Ù…Ù„ Ù„Ù„Ø·Ù„Ø¨
        analysis = await analyze_user_request_advanced(user_prompt)
        
        # ØªØ­Ø¶ÙŠØ± ØªÙ‚Ø±ÙŠØ± Ø§Ù„ØªØ­Ù„ÙŠÙ„
        plan = f"""ðŸ” **ØªØ­Ù„ÙŠÙ„ Ù…ØªÙ‚Ø¯Ù… Ù„Ù„Ø·Ù„Ø¨:**

**Ù†ÙˆØ¹ Ø§Ù„ØªØ´ØºÙŠÙ„:** {analysis.trigger_type}
**Ø§Ù„Ø®Ø¯Ù…Ø§Øª Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø©:** {', '.join(analysis.services)}
**Ø§Ù„Ø¹Ù…Ù„ÙŠØ§Øª:** {', '.join(analysis.operations)}

**Ø§Ù„Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ù…Ø®ØµØµØ©:**
{json.dumps(analysis.custom_names, ensure_ascii=False, indent=2) if analysis.custom_names else 'Ù„Ø§ ØªÙˆØ¬Ø¯ Ø£Ø³Ù…Ø§Ø¡ Ù…Ø®ØµØµØ©'}

**Ø­Ù‚ÙˆÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª:**
{json.dumps(analysis.data_fields, ensure_ascii=False, indent=2)}

**Ù…Ù†Ø·Ù‚ Ø§Ù„Ø¹Ù…Ù„:**
{chr(10).join(f"- {logic}" for logic in analysis.business_logic) if analysis.business_logic else 'Ù…Ù†Ø·Ù‚ Ø£Ø³Ø§Ø³ÙŠ'}

**Ù…Ø³ØªÙˆÙ‰ Ø§Ù„ØªØ¹Ù‚ÙŠØ¯:** {analysis.complexity_score}/10
**Ù…Ø³ØªÙˆÙ‰ Ø§Ù„Ø«Ù‚Ø©:** {analysis.confidence_level}

**Ø·Ù„Ø¨ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ø§Ù„Ø£ØµÙ„ÙŠ:**
{user_prompt}
"""
        
        return plan, True
        
    except Exception as e:
        print(f"[ERROR] Advanced planning failed: {e}")
        # Ø®Ø·Ø© Ø§Ø­ØªÙŠØ§Ø·ÙŠØ©
        return f"ØªØ­Ù„ÙŠÙ„ Ø§Ø­ØªÙŠØ§Ø·ÙŠ Ù„Ù„Ø·Ù„Ø¨: {user_prompt}", False

async def draft_n8n_json_with_ai_advanced(plan: str) -> Tuple[str, bool]:
    """Ø¥Ù†Ø´Ø§Ø¡ workflow Ù…ØªÙ‚Ø¯Ù… ÙˆÙ…Ø®ØµØµ"""
    try:
        # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ù…Ù† Ø§Ù„Ø®Ø·Ø©
        analysis = await analyze_user_request_advanced(plan.split("Ø·Ù„Ø¨ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ø§Ù„Ø£ØµÙ„ÙŠ:")[-1].strip())
        
        # Ø¥Ù†Ø´Ø§Ø¡ builder Ù…ØªÙ‚Ø¯Ù…
        builder = AdvancedN8NBuilder()
        
        # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† workflows Ù…Ù†Ø§Ø³Ø¨Ø© ÙÙŠ Ø§Ù„Ù…ÙƒØªØ¨Ø©
        relevant_workflows = builder.library.find_relevant_workflows(analysis)
        
        print(f"[INFO] Found {len(relevant_workflows)} relevant workflows in library")
        
        # Ø¨Ù†Ø§Ø¡ workflow Ù…Ø®ØµØµ
        custom_workflow = builder.build_custom_workflow(analysis, relevant_workflows)
        
        print("[SUCCESS] Generated advanced custom n8n workflow")
        return json.dumps(custom_workflow, ensure_ascii=False, indent=2), True
        
    except Exception as e:
        print(f"[ERROR] Advanced workflow generation failed: {e}")
        
        # Ø¥Ù†Ø´Ø§Ø¡ workflow Ø§Ø­ØªÙŠØ§Ø·ÙŠ Ù…Ø­Ø³Ù†
        fallback_workflow = _create_enhanced_fallback()
        return json.dumps(fallback_workflow, ensure_ascii=False, indent=2), False

def _create_enhanced_fallback() -> Dict[str, Any]:
    """Ø¥Ù†Ø´Ø§Ø¡ workflow Ø§Ø­ØªÙŠØ§Ø·ÙŠ Ù…Ø­Ø³Ù†"""
    return {
        "active": True,
        "connections": {
            "webhook_node": {
                "main": [[{"node": "process_node", "type": "main", "index": 0}]]
            },
            "process_node": {
                "main": [[{"node": "sheets_node", "type": "main", "index": 0}]]
            }
        },
        "createdAt": datetime.now().isoformat(),
        "updatedAt": datetime.now().isoformat(),
        "id": "1",
        "name": "Enhanced Custom Automation",
        "nodes": [
            {
                "parameters": {
                    "httpMethod": "POST",
                    "path": "custom-form",
                    "responseMode": "onReceived"
                },
                "id": "webhook_node",
                "name": "Custom Webhook",
                "type": "n8n-nodes-base.webhook",
                "typeVersion": 2,
                "position": [240, 300]
            },
            {
                "parameters": {
                    "values": {
                        "string": [
                            {"name": "request_id", "value": "={{ 'REQ-' + new Date().getTime().toString() }}"},
                            {"name": "processed_at", "value": "={{ new Date().toISOString() }}"}
                        ]
                    }
                },
                "id": "process_node",
                "name": "Process Data",
                "type": "n8n-nodes-base.set",
                "typeVersion": 3,
                "position": [460, 300]
            },
            {
                "parameters": {
                    "resource": "sheet",
                    "operation": "appendOrUpdate",
                    "documentId": {"__rl": True, "value": "={{$env.GOOGLE_SHEET_ID}}", "mode": "id"},
                    "sheetName": {"__rl": True, "value": "Custom Data", "mode": "list"},
                    "columns": {
                        "mappingMode": "defineBelow",
                        "value": {
                            "Request_ID": "={{ $('Process Data').item.json.request_id }}",
                            "Name": "={{ $json.name }}",
                            "Email": "={{ $json.email }}",
                            "Message": "={{ $json.message }}",
                            "Processed_At": "={{ $('Process Data').item.json.processed_at }}"
                        }
                    }
                },
                "id": "sheets_node",
                "name": "Save to Custom Sheet",
                "type": "n8n-nodes-base.googleSheets",
                "typeVersion": 4,
                "position": [680, 300]
            }
        ],
        "settings": {"executionOrder": "v1"},
        "staticData": {},
        "tags": ["custom", "enhanced"],
        "triggerCount": 1,
        "versionId": "1"
    }

# ØªØ­Ø¯ÙŠØ« Ø¨Ø§Ù‚ÙŠ Ø§Ù„ÙˆØ¸Ø§Ø¦Ù
async def test_gemini_connection() -> Dict[str, Any]:
    """Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„Ø§ØªØµØ§Ù„ Ù…Ø¹ Gemini API"""
    if not GEMINI_API_KEY:
        return {"success": False, "error": "GEMINI_API_KEY not configured"}
    
    try:
        result = await _call_gemini_api("Ù‚Ù„ 'Ø§Ù„Ù†Ø¸Ø§Ù… Ø§Ù„Ù…ØªÙ‚Ø¯Ù… ÙŠØ¹Ù…Ù„ Ø¨Ø´ÙƒÙ„ Ù…Ø«Ø§Ù„ÙŠ!'")
        return {"success": True, "response": result, "model": GEMINI_MODEL}
    except Exception as e:
        return {"success": False, "error": str(e)}

def get_available_templates() -> Dict[str, str]:
    """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ù‚ÙˆØ§Ù„Ø¨ Ø§Ù„Ù…ØªØ§Ø­Ø©"""
    return {
        "advanced_form_automation": "Advanced form with custom fields and email automation",
        "scheduled_reporting": "Intelligent scheduled reports with data processing", 
        "multi_service_integration": "Complex workflows connecting multiple services",
        "conditional_automation": "Smart automation with business logic and conditions"
    }
